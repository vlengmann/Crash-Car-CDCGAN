{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5deaa7d6-0ab5-492c-ad1a-deb252adc330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\vsproj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#image class processing\n",
    "from PIL import Image\n",
    "\n",
    "#for progress bar\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e796f6-d97e-4a86-8238-fcd9f4b123a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Acc', 'Nat']\n",
      "Classes to index : {'Acc': 0, 'Nat': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\Owner\\Documents\\datsci\\Pythonic\\archive (2)\\CCIH\"\n",
    "\n",
    "# 64x64 RGB, TANH-style normalization\n",
    "train_transform_64 = transforms.Compose([\n",
    "    transforms.ToImage(),                # ensure tensor\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToDtype(torch.float32, scale=True),  # [0,1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])       # -> [-1,1]\n",
    "])\n",
    "\n",
    "eval_transform_64 = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset_64 = ImageFolder(root=file_path + r\"\\train\",\n",
    "                               transform=train_transform_64)\n",
    "\n",
    "gan_train_dataset_64 = ImageFolder(root=file_path + r\"\\train\",\n",
    "                                   transform=eval_transform_64)\n",
    "\n",
    "valid_dataset_64 = ImageFolder(root=file_path + r\"\\valid\",\n",
    "                               transform=eval_transform_64)\n",
    "\n",
    "test_dataset_64  = ImageFolder(root=file_path + r\"\\test\",\n",
    "                               transform=eval_transform_64)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_64     = DataLoader(train_dataset_64,     batch_size=batch_size, shuffle=True)\n",
    "gan_train_loader_64 = DataLoader(gan_train_dataset_64, batch_size=batch_size, shuffle=True)\n",
    "valid_loader_64     = DataLoader(valid_dataset_64,     batch_size=batch_size, shuffle=True)\n",
    "test_loader_64      = DataLoader(test_dataset_64,      batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_classes = 2\n",
    "print(\"Classes:\", train_dataset_64.classes)\n",
    "print(\"Classes to index :\", train_dataset_64.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7beb6cbe-7599-41b0-b77d-f83c305f1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrashClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # (3, 64, 64) -> (64, 32, 32)\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # (64, 32, 32) -> (128, 16, 16)\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # (128, 16, 16) -> (256, 8, 8)\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # (256, 8, 8) -> (512, 4, 4)\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a5b32a-8543-4422-9ef6-fd0c850e2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_epoch(data_loader, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total += len(y)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc  = total_correct / total\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def eval_classifier_epoch(data_loader, model, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            total_loss += loss.item() * len(y)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total += len(y)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc  = total_correct / total\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ed4933-51e6-4d2b-9eb9-7ec14a0d6423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 00 | train_loss=0.554, train_acc=0.819 | valid_loss=0.753, valid_acc=0.779\n",
      "[Baseline] Epoch 01 | train_loss=0.149, train_acc=0.943 | valid_loss=1.168, valid_acc=0.746\n",
      "[Baseline] Epoch 02 | train_loss=0.093, train_acc=0.969 | valid_loss=1.066, valid_acc=0.730\n",
      "[Baseline] Epoch 03 | train_loss=0.065, train_acc=0.983 | valid_loss=1.563, valid_acc=0.697\n",
      "[Baseline] Epoch 04 | train_loss=0.057, train_acc=0.981 | valid_loss=1.629, valid_acc=0.697\n",
      "[Baseline] Epoch 05 | train_loss=0.041, train_acc=0.978 | valid_loss=2.027, valid_acc=0.713\n",
      "[Baseline] Epoch 06 | train_loss=0.040, train_acc=0.985 | valid_loss=1.246, valid_acc=0.746\n",
      "[Baseline] Epoch 07 | train_loss=0.036, train_acc=0.987 | valid_loss=1.662, valid_acc=0.738\n",
      "[Baseline] Epoch 08 | train_loss=0.042, train_acc=0.980 | valid_loss=1.517, valid_acc=0.713\n",
      "[Baseline] Epoch 09 | train_loss=0.041, train_acc=0.985 | valid_loss=1.261, valid_acc=0.705\n",
      "\n",
      "Baseline Test: loss=1.600, acc=0.585\n"
     ]
    }
   ],
   "source": [
    "baseline_model_64 = CrashClassifierCNN(num_classes=2)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer_base = torch.optim.Adam(baseline_model_64.parameters(), lr=1e-3)\n",
    "\n",
    "num_cls_epochs = 10  # you can increase later\n",
    "\n",
    "for epoch in range(num_cls_epochs):\n",
    "    train_loss, train_acc = train_classifier_epoch(\n",
    "        train_loader_64, baseline_model_64, optimizer_base, ce_loss\n",
    "    )\n",
    "    valid_loss, valid_acc = eval_classifier_epoch(\n",
    "        valid_loader_64, baseline_model_64, ce_loss\n",
    "    )\n",
    "    print(\n",
    "        f\"[Baseline] Epoch {epoch:02d} | \"\n",
    "        f\"train_loss={train_loss:.3f}, train_acc={train_acc:.3f} | \"\n",
    "        f\"valid_loss={valid_loss:.3f}, valid_acc={valid_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "test_loss_base, test_acc_base = eval_classifier_epoch(\n",
    "    test_loader_64, baseline_model_64, ce_loss\n",
    ")\n",
    "print(f\"\\nBaseline Test: loss={test_loss_base:.3f}, acc={test_acc_base:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42ddffc-17a1-43fb-9723-9419450531d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim   = 100\n",
    "num_classes  = 2\n",
    "total_latent_dim = latent_dim + num_classes  # noise + one-hot labels\n",
    "\n",
    "# Generator: (noise+label) -> (3, 64, 64)\n",
    "generator_cnn = nn.Sequential(\n",
    "    nn.Linear(total_latent_dim, 4 * 4 * 512),\n",
    "    nn.Unflatten(1, (512, 4, 4)),\n",
    "\n",
    "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(128, 64,  kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh()   # -> [-1, 1]\n",
    ")\n",
    "\n",
    "# Discriminator: (image + label maps) -> realism logit\n",
    "in_channels_D = 3 + num_classes\n",
    "\n",
    "discriminator_cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels_D, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "    nn.Flatten(1),\n",
    "    nn.Linear(512 * 4 * 4, 1)   # BCEWithLogitsLoss\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fefc62-ad9c-435f-a945-8ac521a73bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan_epoch(data_loader,\n",
    "                    discriminator,\n",
    "                    generator,\n",
    "                    discriminator_optimizer,\n",
    "                    generator_optimizer,\n",
    "                    loss_function,\n",
    "                    latent_dim,\n",
    "                    num_classes):\n",
    "\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "\n",
    "    total_d_loss = 0.0\n",
    "    total_g_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for real, labels in data_loader:\n",
    "        batch_size = real.size(0)\n",
    "        total_batches += 1\n",
    "\n",
    "        # one-hot labels\n",
    "        y_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "        # label maps for D: expand to (N, num_classes, H, W)\n",
    "        label_maps = y_onehot.unsqueeze(2).unsqueeze(3).expand(\n",
    "            -1, -1, real.size(2), real.size(3)\n",
    "        )\n",
    "\n",
    "        ########################\n",
    "        # 1. Train Discriminator\n",
    "        ########################\n",
    "        Z = torch.randn(batch_size, latent_dim)\n",
    "        Z_cond = torch.cat((Z, y_onehot), dim=1)\n",
    "        fake = generator(Z_cond)   # (N, 3, 64, 64)\n",
    "\n",
    "        real_input = torch.cat((real, label_maps), dim=1)\n",
    "        fake_input = torch.cat((fake, label_maps), dim=1)\n",
    "\n",
    "        X_disc = torch.cat((real_input, fake_input), dim=0)\n",
    "        y_disc = torch.cat(\n",
    "            (torch.ones(batch_size), torch.zeros(batch_size))\n",
    "        ).unsqueeze(1)\n",
    "\n",
    "        pred = discriminator(X_disc)\n",
    "        loss_d = loss_function(pred, y_disc)\n",
    "\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        loss_d.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        total_d_loss += loss_d.item()\n",
    "\n",
    "        ########################\n",
    "        # 2. Train Generator\n",
    "        ########################\n",
    "        Z = torch.randn(batch_size, latent_dim)\n",
    "        Z_cond = torch.cat((Z, y_onehot), dim=1)\n",
    "        gen_fake = generator(Z_cond)\n",
    "\n",
    "        gen_fake_input = torch.cat((gen_fake, label_maps), dim=1)\n",
    "        y_gen = torch.ones(batch_size).unsqueeze(1)\n",
    "\n",
    "        pred_fake = discriminator(gen_fake_input)\n",
    "        loss_g = loss_function(pred_fake, y_gen)\n",
    "\n",
    "        generator_optimizer.zero_grad()\n",
    "        loss_g.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        total_g_loss += loss_g.item()\n",
    "\n",
    "    avg_d_loss = total_d_loss / total_batches\n",
    "    avg_g_loss = total_g_loss / total_batches\n",
    "\n",
    "    return total_d_loss, avg_d_loss, total_g_loss, avg_g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdf199-6c98-464d-802e-d5d9e95308ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GAN] Epoch 00 | D_loss=0.051 | G_loss=0.394\n",
      "[GAN] Epoch 01 | D_loss=0.001 | G_loss=0.070\n"
     ]
    }
   ],
   "source": [
    "loss_function_gan = nn.BCEWithLogitsLoss()\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(\n",
    "    discriminator_cnn.parameters(), lr=2e-4, betas=(0.5, 0.999)\n",
    ")\n",
    "generator_optimizer = torch.optim.Adam(\n",
    "    generator_cnn.parameters(), lr=2e-4, betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "num_gan_epochs = 40  # more than before\n",
    "\n",
    "for epoch in range(num_gan_epochs):\n",
    "    total_d, avg_d, total_g, avg_g = train_gan_epoch(\n",
    "        gan_train_loader_64,\n",
    "        discriminator_cnn,\n",
    "        generator_cnn,\n",
    "        discriminator_optimizer,\n",
    "        generator_optimizer,\n",
    "        loss_function_gan,\n",
    "        latent_dim,\n",
    "        num_classes\n",
    "    )\n",
    "    print(f\"[GAN] Epoch {epoch:02d} | D_loss={avg_d:.3f} | G_loss={avg_g:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710d8b3-4230-4e56-a9a6-ccd812235df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_conditioned_fake_images(generator, class_label, n_samples=16):\n",
    "    labels = torch.full((n_samples,), class_label, dtype=torch.long)\n",
    "    y_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "    Z = torch.randn(n_samples, latent_dim)\n",
    "    Z_cond = torch.cat((Z, y_onehot), dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = generator(Z_cond)   # (n_samples, 3, 64, 64)\n",
    "    return fake, labels\n",
    "\n",
    "def to_img(x):\n",
    "    # from [-1,1] to [0,1] for plotting\n",
    "    return (x + 1) / 2\n",
    "\n",
    "# Plot fake crash (class 0)\n",
    "fake_crash, _ = sample_conditioned_fake_images(generator_cnn, class_label=0, n_samples=16)\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(5,5))\n",
    "ax = ax.flatten()\n",
    "for i in range(16):\n",
    "    img = to_img(fake_crash[i]).permute(1,2,0).cpu().numpy()\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_axis_off()\n",
    "plt.suptitle(\"Generated crash vehicles (Class = 0)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot fake intact (class 1)\n",
    "fake_intact, _ = sample_conditioned_fake_images(generator_cnn, class_label=1, n_samples=16)\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(5,5))\n",
    "ax = ax.flatten()\n",
    "for i in range(16):\n",
    "    img = to_img(fake_intact[i]).permute(1,2,0).cpu().numpy()\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_axis_off()\n",
    "plt.suptitle(\"Generated intact vehicles (Class = 1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c92f3-1153-4546-96c3-05eb2a67d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_tensors(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for X, y in loader:\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "    return torch.cat(X_list, dim=0), torch.cat(y_list, dim=0)\n",
    "\n",
    "X_real, y_real = as_tensors(gan_train_loader_64)\n",
    "print(\"Real train:\", X_real.shape, y_real.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09a2ad-2cc7-4f54-b507-0fc5415b1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cgan_samples(generator, n_per_class, latent_dim, num_classes=2):\n",
    "    all_imgs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        labels = torch.full((n_per_class,), c, dtype=torch.long)\n",
    "        y_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "        Z = torch.randn(n_per_class, latent_dim)\n",
    "        Z_cond = torch.cat((Z, y_onehot), dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake = generator(Z_cond)   # (n_per_class, 3, 64, 64)\n",
    "\n",
    "        all_imgs.append(fake)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    X_fake = torch.cat(all_imgs, dim=0)\n",
    "    y_fake = torch.cat(all_labels, dim=0)\n",
    "    return X_fake, y_fake\n",
    "\n",
    "# Count real examples per class\n",
    "n_real_crash  = (y_real == 0).sum().item()\n",
    "n_real_intact = (y_real == 1).sum().item()\n",
    "print(\"Real counts:\", n_real_crash, n_real_intact)\n",
    "\n",
    "# Choose how many fakes per class\n",
    "n_per_class = max(n_real_crash, n_real_intact)\n",
    "\n",
    "X_fake, y_fake = generate_cgan_samples(\n",
    "    generator_cnn,\n",
    "    n_per_class=n_per_class,\n",
    "    latent_dim=latent_dim,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "print(\"Fake set:\", X_fake.shape, y_fake.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32365092-a1f6-4339-9f78-ad98331e6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = torch.cat([X_real, X_fake], dim=0)\n",
    "y_aug = torch.cat([y_real, y_fake], dim=0)\n",
    "\n",
    "aug_dataset = TensorDataset(X_aug, y_aug)\n",
    "aug_loader  = DataLoader(aug_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(\"Augmented train set:\", X_aug.shape, y_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98649cd-9266-44c7-8903-6a7c58fde694",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model = CrashClassifierCNN(num_classes=2)\n",
    "optimizer_aug = torch.optim.Adam(aug_model.parameters(), lr=1e-3)\n",
    "\n",
    "num_aug_epochs = 10  # can increase later\n",
    "\n",
    "for epoch in range(num_aug_epochs):\n",
    "    train_loss, train_acc = train_classifier_epoch(\n",
    "        aug_loader, aug_model, optimizer_aug, ce_loss\n",
    "    )\n",
    "    valid_loss, valid_acc = eval_classifier_epoch(\n",
    "        valid_loader_64, aug_model, ce_loss\n",
    "    )\n",
    "    print(\n",
    "        f\"[GAN-Aug] Epoch {epoch:02d} | \"\n",
    "        f\"train_loss={train_loss:.3f}, train_acc={train_acc:.3f} | \"\n",
    "        f\"valid_loss={valid_loss:.3f}, valid_acc={valid_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "test_loss_aug, test_acc_aug = eval_classifier_epoch(\n",
    "    test_loader_64, aug_model, ce_loss\n",
    ")\n",
    "\n",
    "print(\"\\n=== Final Test Comparison (64x64, RGB, Tanh) ===\")\n",
    "print(f\"Baseline Test:      loss={test_loss_base:.3f}, acc={test_acc_base:.3f}\")\n",
    "print(f\"GAN-Augmented Test: loss={test_loss_aug:.3f}, acc={test_acc_aug:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1efb3f-9664-41ff-9ace-f9bd40fd46d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417bd47-eac3-4a51-8835-2c63d2d20050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
